# 스파크설치
* https://databricks.com/ : 스파크 설치안되면 여기 들어가서 주피터노트북으로 사용가능

## 1. spark 설치
- [https://spark.apache.org/downloads.html](https://spark.apache.org/downloads.html) : 스파크 설치 사이트

- 사이트에서 'Spark release archives' 클릭 후 **'tar -xvzf spark-2.0.0-bin-hadoop2.7.tgz'** 설치
	![image](https://user-images.githubusercontent.com/47033052/66460083-2c9b5880-eab1-11e9-924c-f9e910a2e378.png)  

## 2. 자바 설치
- 자바는 Java SE Development Kit 8u221 
- 링크 : [https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html](https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html)

## 3. 파이썬 설치
- 파이썬 버전은 2.7.x 버전 권장
	- 나는 일단은 3.6.7 존버

## 4. 'winutils.exe' 설치
- 윈도우에서 하둡을 따로 설치한다면 패스해도 되는 과정.
- [https://github.com/steveloughran/winutils/](https://github.com/steveloughran/winutils/)에서 'winutils.exe' 다운로드
	- C:\hadoop\bin\에 winutils.exe 넣기. 

## 4. 경로 설정(윈도우)
- SPARK_HOME : "C:\Users\user\spark-2.0.0-bin-hadoop2.7"
- JAVA_HOME : "C:\Program Files\Java\jdk1.8.0_221"
- HADOOP_HOME : "C:\hadoop"
- Path : %SPARK_HOME%\bin;%JAVA_HOME%\bin;%HADOOP_HOME%\bin;"

## 5. CMD에서 경로 설정이 올바른지 확인
![image](https://user-images.githubusercontent.com/47033052/66466417-a20d2600-eabd-11e9-8866-fd3d862766a3.png)

## 6. Jupyter Notebook으로 Spark사용